# Node.js 爬虫
- 使用 node-crawler 进行爬取，发送http请求，（node-crawler 是基于request模块实现的）
- 结合jsdom，使用类似于jQuery的DOM操作来解析HTML结果
- 将这些结果持久化，使结果既可以被写入文件又可以被存入数据库

```javascript
let Crawler = require('crawler')
let jsdom = require('jsdom')
let c = new Crawler({
  jQuery: jsdom,
  maxConnections: 100,
  forceUTF8: true,
  callback:function(err,result,$){
    let urls = $('#list a');
    console.log(urls)
  }
})

// 如果c.queue 方法中无回调，则调用全局回调
// 如果有回调，则调用传入的回调
c.queue('http://www.biquku.com/0/330/')

```

## 问题记录
- crawler 中`$`默认使用Cheerio
  - `var $ = res.$.load(res.body,{decodeEntities: false});` 来防止乱码